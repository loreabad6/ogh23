{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08ddcae-b4c8-49de-85d1-39f0ab6b469d",
   "metadata": {},
   "source": [
    "# Sentinel-2 data in Python\n",
    "\n",
    "**OpenGeoHub Summer School 2023**\n",
    "\n",
    "- Lorena Abad\n",
    "- 2023-09-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af4a0d-ea00-4cfb-9627-87c1adc6162b",
   "metadata": {},
   "source": [
    "## Accessing data via STAC API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7138230-6a5b-42ac-9fe9-406b7db7d0f5",
   "metadata": {},
   "source": [
    "Libraries needed for this exercise are imported below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9c2dc-4f95-4206-9f38-272ceb2db53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geogif # render gifs from raster images\n",
    "import geopandas as gpd # handle geospatial data frames\n",
    "from IPython.display import Image # visualize URLs\n",
    "import pandas as pd # data wrangling\n",
    "import pystac_client # connecting to the STAC API\n",
    "from rasterio.enums import Resampling # perform resampling operations\n",
    "import rioxarray # handle spatio-temporal arrays\n",
    "import shapely # create vector objects\n",
    "import stackstac # build an on-demand STAC data cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef236f99-1f26-42a5-9507-084c9244b4c2",
   "metadata": {},
   "source": [
    "### Querying data with `pystac-client`\n",
    "\n",
    "[STAC](https://stacspec.org/en) stands for SpatioTemporal Asset Catalog and it is \"a common language to describe geospatial information, so it can more easily be worked with, indexed, and discovered\". \n",
    "\n",
    "[`pystac-client`](https://pystac-client.readthedocs.io/en/stable/quickstart.html#python) allows the querying of a STAC API using Python.\n",
    "\n",
    "There are several APIs available to query data, you can browse them all in the [STAC catalog index](https://stacindex.org/catalogs). Some of these APIs will require authentication to access the data. We will use the [Earth Search](https://www.element84.com/earth-search/) catalog for this notebook, which allows querying data on Amazon Web Services (AWS). The data we will fetch does not require authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c64642-c449-4104-9de3-5f4d395fd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAC API URL \n",
    "api_url = 'https://earth-search.aws.element84.com/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32751f-988d-4f10-82f1-f941c29269b4",
   "metadata": {},
   "source": [
    "To start fetching data, we will open the client. We can see the collections available for this API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30108dfc-e4b0-4bbe-932f-5f24116edf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pystac_client.Client.open(api_url)\n",
    "for collection in client.get_collections():\n",
    "    print(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322d577-0157-405e-92d8-bca5be1ac0d6",
   "metadata": {},
   "source": [
    "Let's focus on Sentinel-2 data level 2a. [Here are the different levels that Sentinel-2 has](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/processing-levels). Level 2a provides atmospherically corrected data representing surface reflectance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934afbf-7bf7-41bc-b097-fa6102397c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection ID\n",
    "collection = 'sentinel-2-l2a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d07e6-224e-4c01-896d-56c5ad97045a",
   "metadata": {},
   "source": [
    "Let's define now the spatial and temporal extent for our query. We will query all scenes intersecting the point coordinates and the time range given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607ee02-4035-4542-8bb9-9fad2135b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates\n",
    "lon = 16.9\n",
    "lat = 52.4\n",
    "# date range\n",
    "datetime = '2022-05-01/2022-10-01'\n",
    "point = shapely.Point(lon, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47acc99-4ed4-4fe5-bb9b-dbbaa80699e1",
   "metadata": {},
   "source": [
    "And we pass these arguments to our search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fa77a-e96f-4f5b-8669-13ec612d44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = client.search(\n",
    "    collections=[collection],\n",
    "    intersects=point,\n",
    "    datetime=datetime,\n",
    "    # query=[\"eo:cloud_cover<10\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99190a9f-6b84-43d0-b77d-2e3f9a3d334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = search.item_collection()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea33a56-854e-4a84-9275-7e890af6f55b",
   "metadata": {},
   "source": [
    "We can view our query as a Geopandas data frame for easier readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde0eee-f9b8-4bce-8706-939931c03622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame.from_features(items.to_dict(), crs=\"epsg:4326\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09465-03b2-4f36-a58f-aedf3e653c4f",
   "metadata": {},
   "source": [
    "This proves useful for example when we want to visualize the cloud cover of our whole collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddd864-d0be-45f2-b3ba-6f3ae5f46c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "ts = df.set_index(\"datetime\").sort_index()[\"eo:cloud_cover\"]\n",
    "ts.plot(title=\"eo:cloud-cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e4c44-82cf-4752-a47f-3846c962c658",
   "metadata": {},
   "source": [
    "Let's explore the properties of one item. But first let's look for an item index with low cloud cover and low nodata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1c3dd-b13b-446f-a473-5f947c7a26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df.loc[(df['eo:cloud_cover'] <= 2) & (df['s2:nodata_pixel_percentage'] <= 10)]\n",
    "df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bddad-50ee-4011-bcce-ed48029c8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items[df_filt.index[0]]\n",
    "item.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfeeee-bfe4-45be-8598-0c0cffd3b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "item.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1dc20-4f04-4a84-b5fd-827312083e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fea7c-e56d-431b-9f06-0d4ac2c02378",
   "metadata": {},
   "source": [
    "We can also take a look at the assets for the item. That is which bands are available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd08b4-fa29-427a-94f0-7e1b59d4c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item.assets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec41e2e-4d68-4101-9b27-b8141fe09605",
   "metadata": {},
   "source": [
    "And we can also preview how this scene looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf3a4a-be0a-4c27-9676-dfdaaffc3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = item.assets[\"thumbnail\"].href\n",
    "Image(url = thumbnail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fea6fd-81c7-4e81-a1d5-0fea3528514a",
   "metadata": {},
   "source": [
    "Let's take a look at one single band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c6273-4441-4589-89bb-acd29abd8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = item.assets[\"red\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a093ce-f2be-45e5-990d-758c009fedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset.extra_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4ae5b-520c-45dd-b86d-0ecb4152f582",
   "metadata": {},
   "source": [
    "And read it with [`rioxarray`](https://corteva.github.io/rioxarray/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bee8cf-9831-4b9d-a6ed-d9b1bf5ff646",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = rioxarray.open_rasterio(item.assets[\"red\"].href, decode_coords=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a6776-ff9b-4054-8b84-1fd8388edce5",
   "metadata": {},
   "source": [
    "We can now plot the data, in this case a subset to speed up the process. That is achieved with the `isel()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b176f-c6a5-4576-9217-9be44a460d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "red.isel(x=slice(2000, 4000), y=slice(8000, 10500)).plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42351e49-fb67-4cac-ad6c-5a13a9cc97c7",
   "metadata": {},
   "source": [
    "What about an RGB representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367baafc-98a9-4c06-b7e5-c4d9f62158e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = rioxarray.open_rasterio(item.assets[\"visual\"].href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d2f37-2e40-43c7-a42c-bb3e0c9c0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.isel(x=slice(2000, 4000), y=slice(8000, 10500)).plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dafa488-d987-4fc6-a173-3f28605e6ab1",
   "metadata": {},
   "source": [
    "### Creating a STAC data cube\n",
    "\n",
    "To work with the STAC items as a data cube we can use the [`stackstac`](https://stackstac.readthedocs.io/en/latest/) package. \n",
    "\n",
    "To limit our data cube size we will create it only focused on the Poznan bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fc886-a456-403c-9a99-77330cced534",
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = gpd.read_file(\"../../data/poznan.geojson\")\n",
    "footprint.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf994f-19b2-40f8-9394-f428206a6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = stackstac.stack(\n",
    "    items,\n",
    "    resolution=100,\n",
    "    bounds_latlon=footprint.total_bounds,\n",
    "    resampling=Resampling.bilinear\n",
    ")\n",
    "cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc327702-0382-4cdd-a1dd-40725fcc0996",
   "metadata": {},
   "source": [
    "We can further wrangle this cube by selecting only RGB bands and creating monthly composites. We can achieve this with `xarray` resample. This are all the [time range formats](https://docs.xarray.dev/en/latest/generated/xarray.cftime_range.html) supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287d082-c972-4cb8-880f-9cd1b02b9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cube.sel(band=[\"red\", \"green\", \"blue\"])\n",
    "monthly = rgb.resample(time=\"MS\").median(\"time\", keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1316c0c-8342-473e-b125-f7bd14ae1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b6182-6e90-4a3a-9b3f-0699dff37932",
   "metadata": {},
   "source": [
    "We will use the `compute()` function from [`dask`](https://docs.dask.org/en/stable/) to read our object in-memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e199d16-ccf3-4761-9fcb-1228bb11f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = monthly.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d9ccf-2ea8-4bc2-bd25-cb08deacec9c",
   "metadata": {},
   "source": [
    "This will make plotting tasks faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b3897-820e-4c8f-9283-2550bd0c26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly.plot.imshow(\n",
    "    col=\"time\",\n",
    "    col_wrap=3,\n",
    "    rgb=\"band\",\n",
    "    robust=True,\n",
    "    size=4,\n",
    "    add_labels=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c80e9-7f79-479a-9e43-c1ecd7edb40b",
   "metadata": {},
   "source": [
    "Let's take a look now at a smaller area to visualize crops around Poznan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68734f0d-b06a-43a1-acd4-4018f6a7ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = gpd.read_file(\"../../data/crops.geojson\")\n",
    "cube = stackstac.stack(\n",
    "    items,\n",
    "    resolution=10,\n",
    "    bounds_latlon=crops.total_bounds,\n",
    "    resampling=Resampling.bilinear\n",
    ")\n",
    "rgb = cube.sel(band=[\"red\", \"green\", \"blue\"])\n",
    "rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a4596-5afb-4c81-a311-ed93a2ce5c00",
   "metadata": {},
   "source": [
    "For a quick view, we can generate a GIF of the Sentinel-2 scenes we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b5472-7a30-41a7-a1cc-a80f9aced3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_crops = geogif.dgif(rgb).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d47321-826b-40e6-a795-8637830d94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc31889-2c3c-4579-9bc3-ed9587815319",
   "metadata": {},
   "source": [
    "We can work on derived calculation, for example, we can compute the NDVI per scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91ddcd-ae73-4ab7-aa4a-37bdddf6a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir, red = cube.sel(band=\"nir\"), cube.sel(band=\"red\")\n",
    "ndvi = (nir - red) / (nir + red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd4514-f29b-406e-ab8f-b526c8aae4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ccb34-29e5-4807-afec-3f828b1235b5",
   "metadata": {},
   "source": [
    "Let's create a composite with the maximum NDVI value for the whole collection over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3faa788-6181-45a0-945d-e554a523e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_comp = ndvi.max(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65f771-aa17-4678-8829-5cf307200f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndvi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc60c6-556c-44a9-a259-3aaded0c3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_comp = ndvi_comp.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5613a9-8384-4bd6-ae46-04b61a7ef84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_comp.plot(vmin=0, vmax=0.8, cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fc91c-d31c-49ea-a048-d1d7c84d6a39",
   "metadata": {},
   "source": [
    "And finally, let's compute the NDVI anomaly, i.e., how much does each pixel from the composite deviates from the mean of the whole collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0c183-23f6-4fc0-b1e1-640b61524f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = ndvi_comp - ndvi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d374483-b401-4f59-80bd-b862fb1fe218",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = anomaly.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3351680-f685-4ecf-b5cc-2c6b563c35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly.plot(cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9881da9-1fd1-41d1-8449-aac19519420a",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "There might be at some point the need to download the scenes that you just queried. To do so you can use the `os` and `urllib` modules that are part of the python standard library as the code snippet below shows. This will download all of the items from your search, so make sure you apply enough filtering so that you don't download data that you don't need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4fc46-c52b-41a0-962e-7176052079b5",
   "metadata": {},
   "source": [
    "``` python\n",
    "download_path = \"path/to/dir\"\n",
    "\n",
    "for item in items:\n",
    "    download_path = os.path.join(item.collection_id, item.id)\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path, exist_ok=True)\n",
    "    for name, asset in item.assets.items():\n",
    "        urllib.request.urlretrieve(asset.href, \n",
    "                                   os.path.join(download_path, \n",
    "                                   os.path.basename(asset.href)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fbcf7-0083-444d-8819-44e587eaa6c0",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Adjust your STAC query accordingly and create a new data cube **grouped by season**. Think about data sizes and play with an AOI of your choice.\n",
    "2. Compute a time series of NDVI values for one crop parcel of your choice. *Hint:* you can easily create a geojson polygon with https://geojson.io/. Take the temporal grouping of your choice, but what would make sense to compare such vegetation values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ddaee-9e78-4ace-bc5a-e21544e6ec4a",
   "metadata": {},
   "source": [
    "## More resources\n",
    "\n",
    "This material was based on the Carpentries introduction to [Geospatial RAster and Vector data in Python](https://carpentries-incubator.github.io/geospatial-python/) and the [EGU23 short course on the same topic by Francesco Nattino and Ou Ku](https://github.com/esciencecenter-digital-skills/2023-04-25-ds-geospatial-python-EGU/tree/main)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
