{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1126c83d-e051-44a3-9868-a46d112ad2d9",
   "metadata": {},
   "source": [
    "# Sentinel-1 data in Python\n",
    "\n",
    "**OpenGeoHub Summer School 2023**\n",
    "\n",
    "- Lorena Abad\n",
    "- 2023-08-31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126015b1-1121-4b7b-ab75-90944aed8c30",
   "metadata": {},
   "source": [
    "## Querying S1-SLC data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863d330-d0e3-486b-b025-dadad045eec7",
   "metadata": {},
   "source": [
    "Sentinel-1 data comes at different levels and provides different products. For applications such as measuring deformation due to tectonic or volcanic activity, quantifying ground subsidence or to generate digital elevation models (DEM), [interferometric SAR (InSAR)](https://en.wikipedia.org/wiki/Interferometric_synthetic-aperture_radar) techniques can be used. \n",
    "\n",
    "To apply such workflows with Sentinel data, we can use [Sentinel-1 Level 1 Single Look Complex](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1/single-look-complex/interferometric-wide-swath) products.\n",
    "\n",
    "![](https://sentinels.copernicus.eu/documents/247904/1824983/Sentinel-1-core-fig-1.jpg)\n",
    "\n",
    "So far, very few cloud computing capabilities are available to compute such complex workflows, therefore, there is still a need to download data. Depending on the application, we will need to download data with certain characteristics. For example, for DEM generation, we will require a pair of Sentinel-1 scenes acquired closely in time and that have a perpendicular baseline between 150 and 300 m. Usually, computing the perpendicular baseline between two images requires the download of the image pairs. \n",
    "\n",
    "To avoid downloading several unnecessary Sentinel-1 scenes, we can make use of the [Alaska Satellite Facility (ASF)](https://search.asf.alaska.edu/) geographic and baseline tools to query the data we need via their API.\n",
    "\n",
    "Libraries needed for this exercise are imported below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58133e26-bfac-40cf-a210-a4e39fe30ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asf_search as asf\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d039b-dc8f-48f7-87e8-95fb3f5f42e5",
   "metadata": {},
   "source": [
    "### Define extent\n",
    "\n",
    "We will define an aoi and a start and end date for our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2fefb-fa65-4687-998e-5042bd74142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = gpd.read_file(\"../../data/poznan.geojson\").to_wkt()\n",
    "date_start = \"2022/05/01\"\n",
    "date_end = \"2022/10/01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc654ae-443e-4150-84ab-f400d3c2ce6e",
   "metadata": {},
   "source": [
    "### Geographical search\n",
    "\n",
    "Now we can use the [`asf_search` Python module](https://docs.asf.alaska.edu/asf_search/basics/) to perform our geographical search. We specify here the platform and the processing level (SLC) that we are looking for, and we limit the results for this exercise to 10 scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1592e-9f1e-41f9-9af9-e811e8439139",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = asf.geo_search(platform=[asf.PLATFORM.SENTINEL1],\n",
    "                          intersectsWith=footprint.geometry[0],\n",
    "                          processingLevel=[asf.PRODUCT_TYPE.SLC],\n",
    "                          start=date_start,\n",
    "                          end=date_end,\n",
    "                          maxResults=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b00e9-8987-443d-9017-48b8771af352",
   "metadata": {},
   "source": [
    "We can then add the results of the query to a pandas dataframe for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f16ebc-94ce-4f0d-a510-2605f1a21da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.DataFrame([p.properties for p in products])\n",
    "products_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd02c2-d6b7-49ed-8f83-2e6f2eef7359",
   "metadata": {},
   "source": [
    "### Baseline search\n",
    "\n",
    "Now that we have scenes that intersect with our defined extent, we can do a baseline search that will allow us to fetch all the S1 scenes that pair with the first S1 result from our geographical query. The baseline search returns a set of products with precomputed perpendicular baselines, so that we can focus our download on the data that we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015b833-1f86-492e-92a5-dcadb38545a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = products[0].stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a85ad-dac5-4e39-99ca-cf07483c7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(stack)} products found in stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d8749-01b7-40ce-9f38-014dc1a33bf5",
   "metadata": {},
   "source": [
    "We can take a look at the data again as a pandas data frame and we will see that the last two columns correspond to the temporal and perpendicular baseline. We also get information on the flight direction (Ascending or Descending pass). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335b1a4-da08-4182-8f91-d27c83ca497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df = pd.DataFrame([p.properties for p in stack])\n",
    "stack_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ffbf3-2e68-48d8-8598-722bb05255c1",
   "metadata": {},
   "source": [
    "To have an idea of how spread our data is, we can plot the temporal and the perpendicular baselines against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014a203-ba54-4b3f-a863-81fd688727b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df.plot.scatter(x=\"temporalBaseline\", y=\"perpendicularBaseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d99d0c-f878-4613-b2d2-6bd1eae37b4f",
   "metadata": {},
   "source": [
    "Ideally, we will filter those values where `temporalBaseline <= 30` and `150 <= perpendicularBaseline <= 300` for instance to get image pairs suitable for DEM generation. So we can filter our data frame for those values. We look for absolute values since the order of the images is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f66ee0-ca9a-4b5c-b176-1321d62a623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df[(abs(stack_df['temporalBaseline']) <= 30) &\n",
    "         (abs(stack_df['perpendicularBaseline']) >= 150) &\n",
    "         (abs(stack_df['perpendicularBaseline']) <= 300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8cc02-e3d6-4c9a-87df-97389f3bef97",
   "metadata": {},
   "source": [
    "We only get one image fitting the characteristics we require. Let's look at its properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82a815-0397-4684-b95c-0cc5007a0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack[416].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2cc0d-6f46-4b72-97fc-17b83030d4a5",
   "metadata": {},
   "source": [
    "Let's also remember this is paired with the original product we calcualted the baselines for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9399d5-aacd-4d50-ac6c-7b97cb50be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "products[0].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a671c-caef-4219-b036-742e0b43a191",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "Finally, with the ASF API we can download our data to further analyse it with, e.g. SNAP. To do so we can make use of the url property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3375e-fcc1-42e9-ba29-f1765d3d456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    products[0].properties['url'],\n",
    "    stack[416].properties['url']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b9f11-426c-4420-abad-0f77b7223203",
   "metadata": {},
   "source": [
    "Once that is set we can use the `download_urls()` function as speccified below to get our data in a desired directory. To download the data we will need [EarthData credentials](https://urs.earthdata.nasa.gov/). This [notebook from the ASF](https://github.com/asfadmin/Discovery-asf_search/blob/master/examples/5-Download.ipynb) describes the authentication process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68114a4-c3fc-4f94-bd88-4a7de7673719",
   "metadata": {},
   "source": [
    "```python\n",
    "asf.download_urls(urls=urls, path='data/s1', session=user_pass_session, processes=5)\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb58a29-ad4a-4cd3-9835-9257158adafd",
   "metadata": {},
   "source": [
    "## Exploring S1-RTC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bceb522c-9ea8-41ae-852c-b2c481e4fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import rioxarray as rio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02433193-0e06-4a91-8b50-fe8276ea1196",
   "metadata": {},
   "source": [
    "Now let's take a look at a bit more processed data that we can directly work with. Still in Level-1 you will see the [Ground Range Detected (GRD) product](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/ground-range-detected) in the figure above. This is S1 data that has been further processed (it has been detected, multi-looked and projected to ground range). The SLC products we queried before preserve phase information and are processed at the natural pixel spacing whereas GRD products contain the detected amplitude and are multi-looked to reduce the impact of speckle.\n",
    "\n",
    "An extra processing step is to perform [Radiometric Terrain Correction](https://planetarycomputer.microsoft.com/dataset/sentinel-1-rtc), and some data providers like Microsfot Planetary Computer make this dataset available worldwide. Feel free to explore the Planetary Computer access options to work on larger datasets if you are interested. \n",
    "\n",
    "In the spirit to avoid the need for you to get credentials for this particular workshop, we will use a [Sentinel-1 RTC dataset for the Contiguous United States (CONUS)](https://registry.opendata.aws/sentinel-1-rtc-indigo/) which is freely accessible. \n",
    "\n",
    "We will access this data using the Amazon Web Services (AWS) CLI directly (with the `awscli` package). Let's explore the available data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a8e87-759f-48c2-bc4d-3eb21561ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sentinel-s1-rtc-indigo/ --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d81ebc-20d6-408c-aad2-5cad72387d7d",
   "metadata": {},
   "source": [
    "To download a scene we can directly request the data as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba024d1c-c67d-4bdb-b66f-50240ea70da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/R/UV/2021/S1B_20210121_12RUV_DSC/Gamma0_VV.tif S1B_20210121_12RUV_DSC/Gamma0_VV.tif --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6f9ee-942c-4a1d-b183-fa62758ad099",
   "metadata": {},
   "source": [
    "The available bands have the prefix `Gamma0`. This is the result of the RTC algorithm. Read more about [the backscatter types here](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#radiometry).\n",
    "\n",
    "We will also see that the data has a suffix, either VV or VH, this is the polarization. That refers to the way data is collected. [Read more about it here](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/product-overview/polarimetry). \n",
    "\n",
    "Let's start exploring the data. For this we will use `rioxarray`. We will set an environment key to establish no sign request for AWS. And we will also be leveraging the tight integration between xarray and dask to lazily read in data via the chunks parameter. \n",
    "\n",
    "We will get both the `vv` and `vh` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c691ea-c15c-4819-9ef4-3982e33c0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd376517-fcaa-4323-9bd5-a1e767a348c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_vv = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/R/UV/2021/S1B_20210121_12RUV_DSC/Gamma0_VV.tif'\n",
    "url_vh = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/R/UV/2021/S1B_20210121_12RUV_DSC/Gamma0_VV.tif'\n",
    "s1_vv = rio.open_rasterio(url_vv, chunks=True)\n",
    "s1_vh = rio.open_rasterio(url_vh, chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fcfdf-f93a-46f7-8b50-8c1099bfe972",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9bb3b6-e5dc-416d-ba99-ab260bb4f2dd",
   "metadata": {},
   "source": [
    "To visualize the data, we can apply a power to dB scale. This transformation applies a logarithmic scale to the data for easier visualisation, but it is not recommended to use this for any computations, since the data gets distorted. We will slice our data for faster visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63801d88-7a3b-4b08-bc0a-508dffb0b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_to_db(input_arr):\n",
    "    return (10*np.log10(np.abs(input_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c67db2-5a5d-4300-b766-d9ac8a3c0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_vv_ss = s1_vv.isel(x=slice(1000, 1500), y=slice(1000, 1500)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a82d33-3775-4d76-b235-b656444d78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_vv = power_to_db(s1_vv_ss).plot(cmap=plt.cm.Greys_r)\n",
    "fg_vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f860f-dce9-4245-8dd5-b1e878c8fd59",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "\n",
    "1. Try to combine the `ss_vv` and `ss_vh` objects together, compute a new band with the result of `VH/VV` and use these three layers to generate a false color RGB composite. What does the RGB composite tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffabe8ec-2f92-42e6-92c4-2b96600c0755",
   "metadata": {},
   "source": [
    "## More resources:\n",
    "\n",
    "Working with Sentinel-1 SLC data can also be done with Python. There are a couple of packages available for this (`snappy` and [`snapista`](https://snap-contrib.github.io/snapista/)), but ESA is currently working on a follow up of the `snappy` package called `esa-snappy` which will be compatible with the upcoming SNAP-10. Since the [developers claim its worth the wait](https://forum.step.esa.int/t/snappy-and-snap-10-release/39606), I would at this point direct you to the webpage where they seem to be documenting basic usage of the tool. So for that [feel free to check this site more or less at the end of August](https://senbox.atlassian.net/wiki/spaces/SNAP/pages/2499051521/Configure+Python+to+use+the+new+SNAP-Python+esa+snappy+interface+SNAP+version+10).\n",
    "\n",
    "A lot of the examples for this notebook, mainly for the RTC processing were adapted from Emma Marshall's excellent tutorial on [Sentinel-1 RTC data workflows with xarray](https://e-marshall.github.io/sentinel1_rtc/intro.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
